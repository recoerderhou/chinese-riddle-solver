{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Environment Variables\nimport os\nimport pandas as pd\nfrom datasets import load_dataset, load_metric\nimport pdb\nimport numpy as np\nimport codecs\n\n\nWANDB_API_KEY = '\\n'\nos.environ['WANDB_MODE'] = 'offline'\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nmodel_checkpoint = \"nghuyong/ernie-1.0\"\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:22.247054Z","iopub.execute_input":"2021-12-18T15:52:22.247309Z","iopub.status.idle":"2021-12-18T15:52:22.252785Z","shell.execute_reply.started":"2021-12-18T15:52:22.247278Z","shell.execute_reply":"2021-12-18T15:52:22.251932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/proriddles/train_new_df.csv')\nprint(train_df.head(4))\n# 加载本地数据集，指定本地路径即可\ndatasets = load_dataset('csv', data_files={'train': '../input/proriddles/train_new_df.csv',\n                                            'val': '../input/proriddles/val_new_df.csv',\n                                          'test':'../input/proriddles/test_new_df.csv'})\nprint(datasets)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:22.255352Z","iopub.execute_input":"2021-12-18T15:52:22.256517Z","iopub.status.idle":"2021-12-18T15:52:22.317232Z","shell.execute_reply.started":"2021-12-18T15:52:22.256481Z","shell.execute_reply":"2021-12-18T15:52:22.316508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**数据预处理**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)#, use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:22.64754Z","iopub.execute_input":"2021-12-18T15:52:22.647936Z","iopub.status.idle":"2021-12-18T15:52:23.763311Z","shell.execute_reply.started":"2021-12-18T15:52:22.647896Z","shell.execute_reply":"2021-12-18T15:52:23.762648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"choice_names = [\"choice0\", \"choice1\", \"choice2\", \"choice3\",\"choice4\"]\n\ndef preprocess_function(examples):\n    # Repeat each first sentence five times to go with the five possibilities of second sentences.\n    first_sentences = [[context] * 5 for context in examples[\"sent1\"]]\n    # Grab all second sentences possible for each context.\n    question_headers = examples[\"sent2\"]\n    second_sentences = [[f\"{header} {examples[choice][i]}\" for choice in choice_names] for i, header in enumerate(question_headers)]\n    \n    # Flatten everything\n    first_sentences = sum(first_sentences, [])\n    second_sentences = sum(second_sentences, [])\n    \n    # for debugging\n    for sent1, sent2 in zip(first_sentences, second_sentences):\n        #print(len(sent1), len(sent2))\n        if type(sent1) != type(\"string\") or type(sent2) != type(\"string\"):\n            print(type(sent1), type(sent2))\n            print(sent1,sent2)\n            pdb.set_trace()\n            \n    # Tokenize    \n    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n    # Un-flatten\n    return {k: [v[i:i+5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:23.765233Z","iopub.execute_input":"2021-12-18T15:52:23.765574Z","iopub.status.idle":"2021-12-18T15:52:23.775215Z","shell.execute_reply.started":"2021-12-18T15:52:23.765534Z","shell.execute_reply":"2021-12-18T15:52:23.774515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"examples = datasets[\"train\"][120:125]\nfeatures = preprocess_function(examples)\nprint(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])\nidx = 1\n[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(5)]","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:23.776493Z","iopub.execute_input":"2021-12-18T15:52:23.777075Z","iopub.status.idle":"2021-12-18T15:52:23.799344Z","shell.execute_reply.started":"2021-12-18T15:52:23.776994Z","shell.execute_reply":"2021-12-18T15:52:23.798677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_datasets = datasets.map(preprocess_function, batched=True)\nencoded_datasets = encoded_datasets.remove_columns(['choice0', 'sent1', 'choice4', 'riddle', 'choice1', 'choice3', 'choice2', 'sent2'])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-18T15:52:23.800377Z","iopub.execute_input":"2021-12-18T15:52:23.801383Z","iopub.status.idle":"2021-12-18T15:52:27.686132Z","shell.execute_reply.started":"2021-12-18T15:52:23.801341Z","shell.execute_reply":"2021-12-18T15:52:27.685386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n\nmodel = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:27.688804Z","iopub.execute_input":"2021-12-18T15:52:27.689075Z","iopub.status.idle":"2021-12-18T15:52:29.898135Z","shell.execute_reply.started":"2021-12-18T15:52:27.689046Z","shell.execute_reply":"2021-12-18T15:52:29.89748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir = './results',\n    warmup_steps = 1000,\n\n    logging_strategy = 'steps',\n    logging_steps = 250,\n    \n    save_strategy = \"epoch\",\n    save_total_limit = 1,\n    load_best_model_at_end=True,\n    \n    evaluation_strategy=\"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs = 5,\n    weight_decay=0.01,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:29.899479Z","iopub.execute_input":"2021-12-18T15:52:29.899846Z","iopub.status.idle":"2021-12-18T15:52:29.911178Z","shell.execute_reply.started":"2021-12-18T15:52:29.89979Z","shell.execute_reply":"2021-12-18T15:52:29.910197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom typing import Optional, Union\nimport torch\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    \"\"\"\n    Data collator that will dynamically pad the inputs for multiple choice received.\n    \"\"\"\n\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n\n    def __call__(self, features):\n        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0][\"input_ids\"])\n        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        \n        # Un-flatten\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        # Add back labels\n        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:29.914157Z","iopub.execute_input":"2021-12-18T15:52:29.914953Z","iopub.status.idle":"2021-12-18T15:52:29.926297Z","shell.execute_reply.started":"2021-12-18T15:52:29.914917Z","shell.execute_reply":"2021-12-18T15:52:29.92559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_predictions):\n    predictions, label_ids = eval_predictions\n    preds = np.argmax(predictions, axis=1)\n    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:29.937738Z","iopub.execute_input":"2021-12-18T15:52:29.93827Z","iopub.status.idle":"2021-12-18T15:52:29.947586Z","shell.execute_reply.started":"2021-12-18T15:52:29.938235Z","shell.execute_reply":"2021-12-18T15:52:29.946918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_datasets[\"train\"],\n    eval_dataset=encoded_datasets[\"val\"],\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer),\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:29.949Z","iopub.execute_input":"2021-12-18T15:52:29.949306Z","iopub.status.idle":"2021-12-18T15:52:30.076332Z","shell.execute_reply.started":"2021-12-18T15:52:29.949271Z","shell.execute_reply":"2021-12-18T15:52:30.075545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T15:52:30.077522Z","iopub.execute_input":"2021-12-18T15:52:30.077776Z","iopub.status.idle":"2021-12-18T16:00:07.329712Z","shell.execute_reply.started":"2021-12-18T15:52:30.077743Z","shell.execute_reply":"2021-12-18T16:00:07.329071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:00:07.331024Z","iopub.execute_input":"2021-12-18T16:00:07.33142Z","iopub.status.idle":"2021-12-18T16:00:12.074202Z","shell.execute_reply.started":"2021-12-18T16:00:07.331382Z","shell.execute_reply":"2021-12-18T16:00:12.073564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, label_ids, metrics= trainer.predict(test_dataset=encoded_datasets['val'])\nwriter = codecs.open(\"./results/valpredict.txt\", 'w', encoding='utf-8')\nfor i in range(len(predictions)):\n    predict_id = np.argmax(predictions[i], axis=-1)\n    writer.write(str(predict_id)+'\\n')\nwriter.write(str(metrics))\nwriter.close()\nprint(metrics)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:00:12.075773Z","iopub.execute_input":"2021-12-18T16:00:12.076293Z","iopub.status.idle":"2021-12-18T16:00:12.090642Z","shell.execute_reply.started":"2021-12-18T16:00:12.076256Z","shell.execute_reply":"2021-12-18T16:00:12.089959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, label_ids, metrics= trainer.predict(test_dataset=encoded_datasets['test'])\nwriter = codecs.open(\"./results/testpredict.txt\", 'w', encoding='utf-8')\nfor i in range(len(predictions)):\n    predict_id = np.argmax(predictions[i], axis=-1)\n    writer.write(str(predict_id)+'\\n')\nwriter.write(str(metrics))\nwriter.close()\nprint(metrics)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:02:37.053016Z","iopub.execute_input":"2021-12-18T16:02:37.053578Z","iopub.status.idle":"2021-12-18T16:02:51.251872Z","shell.execute_reply.started":"2021-12-18T16:02:37.053539Z","shell.execute_reply":"2021-12-18T16:02:51.25118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(v):\n    for i in range(v.shape[0]):\n        norm = np.linalg.norm(v[i])\n        if norm != 0: \n            v[i] = v[i] / norm\n    return v\n\nnp.save('predictions.npy', normalize(predictions))\nnew = np.load('predictions.npy')\nnew","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:03:07.845576Z","iopub.execute_input":"2021-12-18T16:03:07.845841Z","iopub.status.idle":"2021-12-18T16:03:07.895944Z","shell.execute_reply.started":"2021-12-18T16:03:07.845797Z","shell.execute_reply":"2021-12-18T16:03:07.894837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(new.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:01:44.835917Z","iopub.execute_input":"2021-12-18T16:01:44.836191Z","iopub.status.idle":"2021-12-18T16:01:44.847799Z","shell.execute_reply.started":"2021-12-18T16:01:44.83616Z","shell.execute_reply":"2021-12-18T16:01:44.84709Z"},"trusted":true},"execution_count":null,"outputs":[]}]}