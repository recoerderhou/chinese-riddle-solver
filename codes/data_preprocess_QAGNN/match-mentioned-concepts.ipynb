{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"PATTERN_PATH = None\nCPNET_VOCAB = None\nnlp = None\nmatcher = None","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:18:54.585840Z","iopub.execute_input":"2021-12-18T05:18:54.586139Z","iopub.status.idle":"2021-12-18T05:18:54.596047Z","shell.execute_reply.started":"2021-12-18T05:18:54.586108Z","shell.execute_reply":"2021-12-18T05:18:54.595157Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"blacklist = set([\"这个\", \"那个\", \"可能\", \"或许\", \"有些\",\"有人\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:18:54.597552Z","iopub.execute_input":"2021-12-18T05:18:54.597791Z","iopub.status.idle":"2021-12-18T05:18:54.609043Z","shell.execute_reply.started":"2021-12-18T05:18:54.597764Z","shell.execute_reply":"2021-12-18T05:18:54.608190Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"pip install spacy","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-18T05:18:54.617571Z","iopub.execute_input":"2021-12-18T05:18:54.617998Z","iopub.status.idle":"2021-12-18T05:19:03.135331Z","shell.execute_reply.started":"2021-12-18T05:18:54.617957Z","shell.execute_reply":"2021-12-18T05:19:03.134053Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"pip install '../input/raw-chineseconceptnet/zh_core_web_sm-3.1.0/dist/zh_core_web_sm-3.1.0.tar'","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-18T05:19:03.137815Z","iopub.execute_input":"2021-12-18T05:19:03.138068Z","iopub.status.idle":"2021-12-18T05:19:19.557178Z","shell.execute_reply.started":"2021-12-18T05:19:03.138040Z","shell.execute_reply":"2021-12-18T05:19:19.556229Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"import json\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.558994Z","iopub.execute_input":"2021-12-18T05:19:19.559271Z","iopub.status.idle":"2021-12-18T05:19:19.563460Z","shell.execute_reply.started":"2021-12-18T05:19:19.559243Z","shell.execute_reply":"2021-12-18T05:19:19.562554Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"from spacy.matcher import Matcher\nfrom tqdm import tqdm\nimport nltk","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.565537Z","iopub.execute_input":"2021-12-18T05:19:19.565970Z","iopub.status.idle":"2021-12-18T05:19:19.577318Z","shell.execute_reply.started":"2021-12-18T05:19:19.565903Z","shell.execute_reply":"2021-12-18T05:19:19.576487Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"def load_cpnet_vocab(cpnet_vocab_path):\n    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n        cpnet_vocab = [l.strip() for l in fin]\n    cpnet_vocab = [c.replace(\"_\", \" \") for c in cpnet_vocab]\n    return cpnet_vocab","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.579837Z","iopub.execute_input":"2021-12-18T05:19:19.580098Z","iopub.status.idle":"2021-12-18T05:19:19.589039Z","shell.execute_reply.started":"2021-12-18T05:19:19.580071Z","shell.execute_reply":"2021-12-18T05:19:19.588252Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"def lemmatize(nlp, concept):\n    doc = nlp(concept.replace(\"_\", \" \"))\n    lcs = set()\n    lcs.add(\"_\".join([token.text for token in doc]))  # all lemma\n    return lcs","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.590733Z","iopub.execute_input":"2021-12-18T05:19:19.591160Z","iopub.status.idle":"2021-12-18T05:19:19.606238Z","shell.execute_reply.started":"2021-12-18T05:19:19.591119Z","shell.execute_reply":"2021-12-18T05:19:19.605393Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"def load_matcher(nlp, pattern_path):\n    with open(pattern_path, \"r\", encoding=\"utf8\") as fin:\n        all_patterns = json.load(fin)\n\n    matcher = Matcher(nlp.vocab)\n    for concept, pattern in all_patterns.items():\n        matcher.add(concept, [pattern])\n    return matcher","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.607686Z","iopub.execute_input":"2021-12-18T05:19:19.608034Z","iopub.status.idle":"2021-12-18T05:19:19.619294Z","shell.execute_reply.started":"2021-12-18T05:19:19.607988Z","shell.execute_reply":"2021-12-18T05:19:19.618387Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"def hard_ground(nlp, sent, cpnet_vocab):\n    doc = nlp(sent)\n    res = set()\n    for t in doc:\n        if t.text in cpnet_vocab:\n            res.add(t.text)\n    sent = \" \".join([t.text for t in doc])\n    if sent in cpnet_vocab:\n        res.add(sent)\n    if len(res) == 0:\n        for t in doc:\n            for char in t.text:\n                if char in cpnet_vocab:\n                    res.add(char)\n    try:\n        assert len(res) > 0\n    except Exception:\n        print(f\"for {sent}, concept not found in hard grounding.\")\n    return res","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.620364Z","iopub.execute_input":"2021-12-18T05:19:19.621039Z","iopub.status.idle":"2021-12-18T05:19:19.631353Z","shell.execute_reply.started":"2021-12-18T05:19:19.621007Z","shell.execute_reply":"2021-12-18T05:19:19.630673Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"def ground_mentioned_concepts(nlp, matcher, s, ans=None):\n\n    s = s.lower()\n    doc = nlp(s)\n    matches = matcher(doc)\n\n    mentioned_concepts = set()\n    span_to_concepts = {}\n\n    for match_id, start, end in matches:\n\n        span = doc[start:end].text  # the matched span\n\n        # a word that appears in answer is not considered as a mention in the question\n        # if len(set(span.split(\" \")).intersection(set(ans.split(\" \")))) > 0:\n        #     continue\n        original_concept = nlp.vocab.strings[match_id]\n        original_concept_set = set()\n        original_concept_set.add(original_concept)\n\n        # print(\"span\", span)\n        # print(\"concept\", original_concept)\n        # print(\"Matched '\" + span + \"' to the rule '\" + string_id)\n\n        # why do you lemmatize a mention whose len == 1?\n\n        if len(original_concept.split(\"_\")) == 1:\n            # tag = doc[start].tag_\n            # if tag in ['VBN', 'VBG']:\n            original_concept_set.update(lemmatize(nlp, nlp.vocab.strings[match_id]))\n\n        if span not in span_to_concepts:\n            span_to_concepts[span] = set()\n\n        span_to_concepts[span].update(original_concept_set)\n\n    for span, concepts in span_to_concepts.items():\n        concepts_sorted = list(concepts)\n        concepts_sorted.sort(key=len)\n\n        shortest = concepts_sorted[0:3]\n\n        for c in shortest:\n            if c in blacklist:\n                continue\n            # a set with one string like: set(\"like_apples\")\n            lcs = lemmatize(nlp, c)\n            intersect = lcs.intersection(shortest)\n            if len(intersect) > 0:\n                mentioned_concepts.add(list(intersect)[0])\n            else:\n                mentioned_concepts.add(c)\n\n        # if a mention exactly matches with a concept\n\n        exact_match = set([concept for concept in concepts_sorted if concept.replace(\"_\", \" \").lower() == span.lower()])\n        # print(\"exact match:\")\n        # print(exact_match)\n        assert len(exact_match) < 2\n        mentioned_concepts.update(exact_match)\n\n    return mentioned_concepts","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.632652Z","iopub.execute_input":"2021-12-18T05:19:19.633020Z","iopub.status.idle":"2021-12-18T05:19:19.646089Z","shell.execute_reply.started":"2021-12-18T05:19:19.632991Z","shell.execute_reply":"2021-12-18T05:19:19.645257Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"def ground_qa_pair(s, a):\n    global nlp, matcher\n    if nlp is None or matcher is None:\n        nlp = spacy.load('zh_core_web_sm', disable=['ner', 'parser', 'textcat'])\n        matcher = load_matcher(nlp, PATTERN_PATH)\n\n    all_concepts = ground_mentioned_concepts(nlp, matcher, s, a)\n    answer_concepts = ground_mentioned_concepts(nlp, matcher, a)\n    question_concepts = all_concepts - answer_concepts\n    if len(question_concepts) == 0:\n        if len(question_concepts) <= 5:\n            print(question_concepts)\n        question_concepts = hard_ground(nlp, s, CPNET_VOCAB)  # not very possible\n\n    if len(answer_concepts) == 0:\n        answer_concepts = hard_ground(nlp, a, CPNET_VOCAB)  # some case\n\n    # question_concepts = question_concepts -  answer_concepts\n    question_concepts = sorted(list(question_concepts))\n    answer_concepts = sorted(list(answer_concepts))\n    return {\"sent\": s, \"ans\": a, \"qc\": question_concepts, \"ac\": answer_concepts}","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.647428Z","iopub.execute_input":"2021-12-18T05:19:19.647719Z","iopub.status.idle":"2021-12-18T05:19:19.663042Z","shell.execute_reply.started":"2021-12-18T05:19:19.647679Z","shell.execute_reply":"2021-12-18T05:19:19.662407Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"def prune(data, cpnet_vocab_path):\n    # reload cpnet_vocab\n    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n        cpnet_vocab = [l.strip() for l in fin]\n\n    prune_data = []\n    for item in tqdm(data):\n        qc = item[\"qc\"]\n        prune_qc = []\n        for c in qc:\n            # remove all concepts having stopwords, including hard-grounded ones\n            if c in cpnet_vocab:\n                prune_qc.append(c)\n\n        ac = item[\"ac\"]\n        prune_ac = []\n        for c in ac:\n            if c in cpnet_vocab:\n                prune_ac.append(c)\n\n        try:\n            assert len(prune_ac) > 0 and len(prune_qc) > 0\n        except Exception as e:\n            pass\n        item[\"qc\"] = prune_qc\n        item[\"ac\"] = prune_ac\n\n        prune_data.append(item)\n    return prune_data","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.664512Z","iopub.execute_input":"2021-12-18T05:19:19.665167Z","iopub.status.idle":"2021-12-18T05:19:19.678835Z","shell.execute_reply.started":"2021-12-18T05:19:19.665124Z","shell.execute_reply":"2021-12-18T05:19:19.677853Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"def ground(statement_path, cpnet_vocab_path, pattern_path, output_path, num_processes=1, debug=False):\n    global PATTERN_PATH, CPNET_VOCAB\n    if PATTERN_PATH is None:\n        PATTERN_PATH = pattern_path\n        CPNET_VOCAB = load_cpnet_vocab(cpnet_vocab_path)\n\n    sents = []\n    answers = []\n    with open(statement_path, 'r') as fin:\n        lines = [line for line in fin]\n\n    if debug:\n        lines = lines[192:195]\n        print(len(lines))\n    for line in lines:\n        if line == \"\":\n            continue\n        j = json.loads(line)\n        # {'answerKey': 'B',\n        #   'id': 'b8c0a4703079cf661d7261a60a1bcbff',\n        #   'question': {'question_concept': 'magazines',\n        #                 'choices': [{'label': 'A', 'text': 'doctor'}, {'label': 'B', 'text': 'bookstore'}, {'label': 'C', 'text': 'market'}, {'label': 'D', 'text': 'train station'}, {'label': 'E', 'text': 'mortuary'}],\n        #                 'stem': 'Where would you find magazines along side many other printed works?'},\n        #   'statements': [{'label': False, 'statement': 'Doctor would you find magazines along side many other printed works.'}, {'label': True, 'statement': 'Bookstore would you find magazines along side many other printed works.'}, {'label': False, 'statement': 'Market would you find magazines along side many other printed works.'}, {'label': False, 'statement': 'Train station would you find magazines along side many other printed works.'}, {'label': False, 'statement': 'Mortuary would you find magazines along side many other printed works.'}]}\n\n        for statement in j[\"statements\"]:\n            sents.append(statement[\"statement\"])\n\n        for answer in j[\"question\"][\"choices\"]:\n            ans = answer['text']\n            # ans = \" \".join(answer['text'].split(\"_\"))\n            try:\n                assert all([i != \"_\" for i in ans])\n            except Exception:\n                print(ans)\n            answers.append(ans)\n\n    res = [ground_qa_pair(sent, answer) for sent, answer in zip(sents, answers)]\n    res = prune(res, cpnet_vocab_path)\n\n    # check_path(output_path)\n    with open(output_path, 'w') as fout:\n        for dic in res:\n            fout.write(json.dumps(dic) + '\\n')\n\n    print(f'grounded concepts saved to {output_path}')\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:19:19.680831Z","iopub.execute_input":"2021-12-18T05:19:19.681255Z","iopub.status.idle":"2021-12-18T05:19:19.694274Z","shell.execute_reply.started":"2021-12-18T05:19:19.681203Z","shell.execute_reply":"2021-12-18T05:19:19.693590Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"statement_path = '../input/new-json-little-soldier/train.statement_zh.jsonl'\ncpnet_vocab_path = '../input/raw-chineseconceptnet/concept.txt'\npattern_path = '../input/new-json-little-soldier/matcher_patterns.zh.json'\noutput_path = 'train.grounded_zh.jsonl'\nground(statement_path, cpnet_vocab_path, pattern_path, output_path)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-18T05:19:19.695656Z","iopub.execute_input":"2021-12-18T05:19:19.696168Z","iopub.status.idle":"2021-12-18T06:30:52.683412Z","shell.execute_reply.started":"2021-12-18T05:19:19.696132Z","shell.execute_reply":"2021-12-18T06:30:52.682448Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"statement_path = '../input/new-json-little-soldier/val.statement_zh.jsonl'\noutput_path = 'val.grounded_zh.jsonl'\nground(statement_path, cpnet_vocab_path, pattern_path, output_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:39:39.710411Z","iopub.execute_input":"2021-12-18T06:39:39.710768Z","iopub.status.idle":"2021-12-18T06:48:28.411414Z","shell.execute_reply.started":"2021-12-18T06:39:39.710734Z","shell.execute_reply":"2021-12-18T06:48:28.410656Z"},"scrolled":true,"trusted":true},"execution_count":232,"outputs":[]}]}