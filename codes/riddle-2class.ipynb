{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"先导入数据集","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ntrainpath = \"/kaggle/input/littlesoldierriddle/train_judge_4.csv\"\nvalidpath = \"/kaggle/input/littlesoldierriddle/valid_judge.csv\"\ntestpath = \"/kaggle/input/littlesoldierriddle/test_judge.csv\"\ndata_files = {\"train\": trainpath, \"valid\": validpath, \"test\": testpath}\nriddle_dataset = load_dataset(\"csv\", data_files=data_files, encoding='gb18030')\n#riddle_dataset = load_dataset(\"csv\", data_files=data_files)\n\nriddle_shuffle = riddle_dataset[\"train\"].shuffle(seed=42).select((range(32000)))\n\nprint(riddle_shuffle)\n#print(riddle_shuffle[:3])\nprint(riddle_dataset[\"valid\"][0])\nprint(riddle_shuffle.features)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T20:36:18.375281Z","iopub.execute_input":"2021-12-17T20:36:18.375636Z","iopub.status.idle":"2021-12-17T20:36:19.042572Z","shell.execute_reply.started":"2021-12-17T20:36:18.375587Z","shell.execute_reply":"2021-12-17T20:36:19.041774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"接下来我们预处理一下数据集","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"nghuyong/ernie-1.0\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\ndef tokenize_function(example):\n    return tokenizer(\n        example[\"riddle\"],\n        example[\"choice\"], \n        truncation=True, \n        max_length=64, \n        #return_overflowing_tokens=True,\n    )\n\ntokenized_datasets = {}\n\ntokenized_datasets[\"valid\"] = riddle_dataset[\"valid\"].map(\n    tokenize_function, \n    batched=True, \n    #remove_columns=riddle_dataset[\"valid\"].column_names,\n)\n\ntokenized_datasets[\"test\"] = riddle_dataset[\"test\"].map(\n    tokenize_function, \n    batched=True, \n)\n\ntokenized_datasets[\"train\"] = riddle_shuffle.map(\n    tokenize_function, \n    batched=True, \n    #remove_columns=riddle_shuffle.column_names, \n)\n\nprint(tokenized_datasets)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-17T20:36:19.04427Z","iopub.execute_input":"2021-12-17T20:36:19.044706Z","iopub.status.idle":"2021-12-17T20:36:25.802699Z","shell.execute_reply.started":"2021-12-17T20:36:19.044667Z","shell.execute_reply":"2021-12-17T20:36:25.801997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\nimport numpy as np\n\ndef compute_metrics(eval_preds):\n  metric = load_metric(\"glue\", 'mrpc')\n  logits, labels = eval_preds\n  predictions = np.argmax(logits, axis=-1)\n  return metric.compute(predictions=predictions, references=labels)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-17T20:36:25.805358Z","iopub.execute_input":"2021-12-17T20:36:25.805563Z","iopub.status.idle":"2021-12-17T20:36:25.809957Z","shell.execute_reply.started":"2021-12-17T20:36:25.805539Z","shell.execute_reply":"2021-12-17T20:36:25.809229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom transformers import TrainingArguments\nfrom transformers import Trainer\nfrom transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n\n#training_args = TrainingArguments(\"test-trainer\")\ntraining_args = TrainingArguments(\n    output_dir = \"results\", \n    overwrite_output_dir = True,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    per_device_train_batch_size = 16,\n    per_device_eval_batch_size = 16, \n    eval_steps = 500, \n    num_train_epochs = 10,\n    load_best_model_at_end=True, \n)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"valid\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-17T20:36:25.812976Z","iopub.execute_input":"2021-12-17T20:36:25.813449Z","iopub.status.idle":"2021-12-17T21:12:09.779522Z","shell.execute_reply.started":"2021-12-17T20:36:25.813412Z","shell.execute_reply":"2021-12-17T21:12:09.778665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\npredictions = trainer.predict(tokenized_datasets[\"test\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)\nprint(predictions.predictions[:1].shape, predictions.label_ids.shape)\n\npreds = np.argmax(predictions.predictions, axis=-1)\nnp.save(\"preds.npy\", predictions.predictions)\nprint(\"successfully saved\")","metadata":{"execution":{"iopub.status.busy":"2021-12-17T21:12:09.780801Z","iopub.execute_input":"2021-12-17T21:12:09.781068Z","iopub.status.idle":"2021-12-17T21:12:24.315666Z","shell.execute_reply.started":"2021-12-17T21:12:09.781032Z","shell.execute_reply":"2021-12-17T21:12:24.31496Z"},"trusted":true},"execution_count":null,"outputs":[]}]}